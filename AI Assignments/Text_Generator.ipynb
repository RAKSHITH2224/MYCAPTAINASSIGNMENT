{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Text Generation"
      ],
      "metadata": {
        "id": "H6SroxuR57Jy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTOumTh75MM8",
        "outputId": "9983c258-e290-46b2-a74a-286200926196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Import Dependencies\n",
        "import numpy\n",
        "import sys\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "file=open(\"frankenstein.txt\").read()"
      ],
      "metadata": {
        "id": "oO8gcvYs5-Y3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "def tokenize_words(input):\n",
        "    input=input.lower()\n",
        "    tokenizer=RegexpTokenizer(r'\\w+')\n",
        "    tokens=tokenizer.tokenize(input)\n",
        "    filtered=filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "    return \" \".join(filtered)\n",
        "processed_inputs=tokenize_words(file)"
      ],
      "metadata": {
        "id": "UxCGY7JE7gPF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars=sorted(list(set(processed_inputs)))\n",
        "char_to_num=dict((c,i) for i,c in enumerate(chars))"
      ],
      "metadata": {
        "id": "67-qQj2L70J3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if the words to char or chars to num has worked\n",
        "input_len=len(processed_inputs)\n",
        "vocab_len=len(chars)\n",
        "print(\"Total number of characters:\", input_len)\n",
        "print(\"Total vocab:\",vocab_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPi6K0C072HT",
        "outputId": "27a8b0a6-bfec-4f01-e380-2981e15b124e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 195700\n",
            "Total vocab: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sege length\n",
        "seq_length=100\n",
        "x_data=[]\n",
        "y_data=[]"
      ],
      "metadata": {
        "id": "2dI7x9gW740z"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loop through the sequence\n",
        "for i in range(0,input_len-seq_length,1):\n",
        "    in_seq=processed_inputs[i:i+seq_length]\n",
        "    out_seq=processed_inputs[i+seq_length]\n",
        "    x_data.append([char_to_num[char] for char in in_seq])\n",
        "    y_data.append(char_to_num[out_seq])\n",
        "\n",
        "n_patterns=len(x_data)\n",
        "print(\"Total Patterns:\", n_patterns)"
      ],
      "metadata": {
        "id": "ZA0I5TNZ77gD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29c0dce-5c59-4075-fbf0-b985dce0378d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns: 195600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert input sequence to np array and so on\n",
        "X=numpy.reshape(x_data,(n_patterns, seq_length,1))\n",
        "X=X/float(vocab_len)"
      ],
      "metadata": {
        "id": "SkLH9YOD797y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding\n",
        "y = to_categorical(y_data)"
      ],
      "metadata": {
        "id": "f1VcsKkl7_1q"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the model\n",
        "model=Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1],X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1],activation='softmax'))"
      ],
      "metadata": {
        "id": "qHwcbQtX8Ki3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam')"
      ],
      "metadata": {
        "id": "zc5YOkP68Mta"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the weights\n",
        "filepath='model_weights_saved.keras'\n",
        "checkpoint=ModelCheckpoint(filepath, monitor='loss',verbose=1,save_best_only=True,mode='min')\n",
        "desired_callbacks=[checkpoint]"
      ],
      "metadata": {
        "id": "jknvabGN8Qt0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the model and let it train\n",
        "model.fit(X,y,epochs=100,batch_size=256,callbacks=desired_callbacks)"
      ],
      "metadata": {
        "id": "ocZWCnkT8l7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7fc620-2056-4939-9d84-d1d790c7c809"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 2.9491\n",
            "Epoch 1: loss improved from inf to 2.85765, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 81ms/step - loss: 2.9490\n",
            "Epoch 2/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 2.6263\n",
            "Epoch 2: loss improved from 2.85765 to 2.57741, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85ms/step - loss: 2.6262\n",
            "Epoch 3/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 2.4314\n",
            "Epoch 3: loss improved from 2.57741 to 2.37873, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 2.4312\n",
            "Epoch 4/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 2.2383\n",
            "Epoch 4: loss improved from 2.37873 to 2.19952, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 2.2382\n",
            "Epoch 5/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 2.0808\n",
            "Epoch 5: loss improved from 2.19952 to 2.05436, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 2.0807\n",
            "Epoch 6/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.9725\n",
            "Epoch 6: loss improved from 2.05436 to 1.95259, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 1.9724\n",
            "Epoch 7/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.8958\n",
            "Epoch 7: loss improved from 1.95259 to 1.88303, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 85ms/step - loss: 1.8958\n",
            "Epoch 8/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.8289\n",
            "Epoch 8: loss improved from 1.88303 to 1.82351, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.8289\n",
            "Epoch 9/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.7882\n",
            "Epoch 9: loss improved from 1.82351 to 1.77895, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 85ms/step - loss: 1.7882\n",
            "Epoch 10/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.7485\n",
            "Epoch 10: loss improved from 1.77895 to 1.74339, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.7485\n",
            "Epoch 11/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.7200\n",
            "Epoch 11: loss improved from 1.74339 to 1.71050, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.7200\n",
            "Epoch 12/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.6887\n",
            "Epoch 12: loss improved from 1.71050 to 1.68507, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.6887\n",
            "Epoch 13/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.6642\n",
            "Epoch 13: loss improved from 1.68507 to 1.65920, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.6642\n",
            "Epoch 14/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.6312\n",
            "Epoch 14: loss improved from 1.65920 to 1.63605, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 1.6312\n",
            "Epoch 15/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.6167\n",
            "Epoch 15: loss improved from 1.63605 to 1.61601, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 85ms/step - loss: 1.6167\n",
            "Epoch 16/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.5926\n",
            "Epoch 16: loss improved from 1.61601 to 1.59846, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.5926\n",
            "Epoch 17/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.5876\n",
            "Epoch 17: loss improved from 1.59846 to 1.58728, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.5876\n",
            "Epoch 18/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.5706\n",
            "Epoch 18: loss improved from 1.58728 to 1.56891, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 84ms/step - loss: 1.5706\n",
            "Epoch 19/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 1.5535\n",
            "Epoch 19: loss improved from 1.56891 to 1.55065, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 86ms/step - loss: 1.5534\n",
            "Epoch 20/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.5418\n",
            "Epoch 20: loss improved from 1.55065 to 1.54302, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.5418\n",
            "Epoch 21/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.5303\n",
            "Epoch 21: loss improved from 1.54302 to 1.53259, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 1.5303\n",
            "Epoch 22/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.5128\n",
            "Epoch 22: loss improved from 1.53259 to 1.51520, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 85ms/step - loss: 1.5128\n",
            "Epoch 23/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.5048\n",
            "Epoch 23: loss improved from 1.51520 to 1.50563, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 85ms/step - loss: 1.5048\n",
            "Epoch 24/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.4988\n",
            "Epoch 24: loss improved from 1.50563 to 1.49530, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.4988\n",
            "Epoch 25/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.4825\n",
            "Epoch 25: loss improved from 1.49530 to 1.48562, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.4826\n",
            "Epoch 26/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.4750\n",
            "Epoch 26: loss improved from 1.48562 to 1.47764, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.4750\n",
            "Epoch 27/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 1.4642\n",
            "Epoch 27: loss improved from 1.47764 to 1.47038, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 86ms/step - loss: 1.4643\n",
            "Epoch 28/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 1.4584\n",
            "Epoch 28: loss improved from 1.47038 to 1.45999, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 86ms/step - loss: 1.4584\n",
            "Epoch 29/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.4559\n",
            "Epoch 29: loss improved from 1.45999 to 1.45397, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.4559\n",
            "Epoch 30/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.4393\n",
            "Epoch 30: loss improved from 1.45397 to 1.44467, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.4393\n",
            "Epoch 31/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.4294\n",
            "Epoch 31: loss improved from 1.44467 to 1.43911, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.4295\n",
            "Epoch 32/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.4317\n",
            "Epoch 32: loss improved from 1.43911 to 1.43250, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.4317\n",
            "Epoch 33/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.4344\n",
            "Epoch 33: loss improved from 1.43250 to 1.42785, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.4344\n",
            "Epoch 34/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.4205\n",
            "Epoch 34: loss improved from 1.42785 to 1.41851, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 1.4205\n",
            "Epoch 35/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.4041\n",
            "Epoch 35: loss improved from 1.41851 to 1.41111, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 85ms/step - loss: 1.4041\n",
            "Epoch 36/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3991\n",
            "Epoch 36: loss improved from 1.41111 to 1.40500, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3991\n",
            "Epoch 37/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3992\n",
            "Epoch 37: loss improved from 1.40500 to 1.39954, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3992\n",
            "Epoch 38/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3908\n",
            "Epoch 38: loss improved from 1.39954 to 1.39469, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3908\n",
            "Epoch 39/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3902\n",
            "Epoch 39: loss improved from 1.39469 to 1.39084, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3902\n",
            "Epoch 40/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3820\n",
            "Epoch 40: loss improved from 1.39084 to 1.38596, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3820\n",
            "Epoch 41/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3866\n",
            "Epoch 41: loss improved from 1.38596 to 1.38139, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3866\n",
            "Epoch 42/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3667\n",
            "Epoch 42: loss improved from 1.38139 to 1.37492, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3667\n",
            "Epoch 43/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3679\n",
            "Epoch 43: loss improved from 1.37492 to 1.37392, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3679\n",
            "Epoch 44/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3621\n",
            "Epoch 44: loss improved from 1.37392 to 1.36715, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3622\n",
            "Epoch 45/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3582\n",
            "Epoch 45: loss improved from 1.36715 to 1.36080, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3582\n",
            "Epoch 46/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3601\n",
            "Epoch 46: loss improved from 1.36080 to 1.35934, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3601\n",
            "Epoch 47/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3487\n",
            "Epoch 47: loss improved from 1.35934 to 1.35140, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3487\n",
            "Epoch 48/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3514\n",
            "Epoch 48: loss improved from 1.35140 to 1.34952, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3514\n",
            "Epoch 49/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3368\n",
            "Epoch 49: loss improved from 1.34952 to 1.34146, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3368\n",
            "Epoch 50/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3390\n",
            "Epoch 50: loss did not improve from 1.34146\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3390\n",
            "Epoch 51/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3368\n",
            "Epoch 51: loss improved from 1.34146 to 1.34106, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3369\n",
            "Epoch 52/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.3257\n",
            "Epoch 52: loss improved from 1.34106 to 1.33157, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 1.3257\n",
            "Epoch 53/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3303\n",
            "Epoch 53: loss improved from 1.33157 to 1.32842, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 85ms/step - loss: 1.3303\n",
            "Epoch 54/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3225\n",
            "Epoch 54: loss improved from 1.32842 to 1.32535, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3225\n",
            "Epoch 55/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3213\n",
            "Epoch 55: loss improved from 1.32535 to 1.32093, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3213\n",
            "Epoch 56/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.3110\n",
            "Epoch 56: loss improved from 1.32093 to 1.31906, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 1.3111\n",
            "Epoch 57/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3037\n",
            "Epoch 57: loss improved from 1.31906 to 1.31530, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 85ms/step - loss: 1.3037\n",
            "Epoch 58/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.3048\n",
            "Epoch 58: loss improved from 1.31530 to 1.30921, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 1.3048\n",
            "Epoch 59/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3045\n",
            "Epoch 59: loss improved from 1.30921 to 1.30736, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 85ms/step - loss: 1.3046\n",
            "Epoch 60/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.3063\n",
            "Epoch 60: loss did not improve from 1.30736\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.3063\n",
            "Epoch 61/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2977\n",
            "Epoch 61: loss improved from 1.30736 to 1.30311, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2977\n",
            "Epoch 62/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2936\n",
            "Epoch 62: loss improved from 1.30311 to 1.29976, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2936\n",
            "Epoch 63/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2915\n",
            "Epoch 63: loss improved from 1.29976 to 1.29720, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2915\n",
            "Epoch 64/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2902\n",
            "Epoch 64: loss improved from 1.29720 to 1.29459, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2902\n",
            "Epoch 65/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.2895\n",
            "Epoch 65: loss improved from 1.29459 to 1.29327, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 1.2895\n",
            "Epoch 66/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2765\n",
            "Epoch 66: loss improved from 1.29327 to 1.28891, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 85ms/step - loss: 1.2766\n",
            "Epoch 67/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2774\n",
            "Epoch 67: loss improved from 1.28891 to 1.28369, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2774\n",
            "Epoch 68/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2777\n",
            "Epoch 68: loss did not improve from 1.28369\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2777\n",
            "Epoch 69/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2717\n",
            "Epoch 69: loss improved from 1.28369 to 1.27798, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2717\n",
            "Epoch 70/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2760\n",
            "Epoch 70: loss did not improve from 1.27798\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2760\n",
            "Epoch 71/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2746\n",
            "Epoch 71: loss improved from 1.27798 to 1.27742, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 85ms/step - loss: 1.2746\n",
            "Epoch 72/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 1.2699\n",
            "Epoch 72: loss improved from 1.27742 to 1.27230, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 87ms/step - loss: 1.2699\n",
            "Epoch 73/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2596\n",
            "Epoch 73: loss improved from 1.27230 to 1.26676, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 85ms/step - loss: 1.2596\n",
            "Epoch 74/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2698\n",
            "Epoch 74: loss did not improve from 1.26676\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2698\n",
            "Epoch 75/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2527\n",
            "Epoch 75: loss improved from 1.26676 to 1.26527, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2527\n",
            "Epoch 76/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.2559\n",
            "Epoch 76: loss improved from 1.26527 to 1.26272, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 1.2559\n",
            "Epoch 77/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 1.2548\n",
            "Epoch 77: loss improved from 1.26272 to 1.25930, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 86ms/step - loss: 1.2548\n",
            "Epoch 78/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2517\n",
            "Epoch 78: loss improved from 1.25930 to 1.25775, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2517\n",
            "Epoch 79/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2466\n",
            "Epoch 79: loss improved from 1.25775 to 1.25627, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2466\n",
            "Epoch 80/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2502\n",
            "Epoch 80: loss did not improve from 1.25627\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2502\n",
            "Epoch 81/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2584\n",
            "Epoch 81: loss improved from 1.25627 to 1.25418, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2583\n",
            "Epoch 82/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.2399\n",
            "Epoch 82: loss improved from 1.25418 to 1.24794, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 85ms/step - loss: 1.2400\n",
            "Epoch 83/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2317\n",
            "Epoch 83: loss improved from 1.24794 to 1.24488, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 85ms/step - loss: 1.2318\n",
            "Epoch 84/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2391\n",
            "Epoch 84: loss did not improve from 1.24488\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 85ms/step - loss: 1.2391\n",
            "Epoch 85/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2376\n",
            "Epoch 85: loss improved from 1.24488 to 1.24203, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 86ms/step - loss: 1.2376\n",
            "Epoch 86/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2380\n",
            "Epoch 86: loss did not improve from 1.24203\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2380\n",
            "Epoch 87/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.2310\n",
            "Epoch 87: loss improved from 1.24203 to 1.23743, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 85ms/step - loss: 1.2310\n",
            "Epoch 88/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2365\n",
            "Epoch 88: loss did not improve from 1.23743\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 85ms/step - loss: 1.2365\n",
            "Epoch 89/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.2236\n",
            "Epoch 89: loss improved from 1.23743 to 1.23123, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 84ms/step - loss: 1.2237\n",
            "Epoch 90/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2291\n",
            "Epoch 90: loss did not improve from 1.23123\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2291\n",
            "Epoch 91/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2194\n",
            "Epoch 91: loss improved from 1.23123 to 1.23113, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2194\n",
            "Epoch 92/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2224\n",
            "Epoch 92: loss improved from 1.23113 to 1.23016, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2225\n",
            "Epoch 93/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2209\n",
            "Epoch 93: loss improved from 1.23016 to 1.22835, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2210\n",
            "Epoch 94/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.2199\n",
            "Epoch 94: loss improved from 1.22835 to 1.22650, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 1.2200\n",
            "Epoch 95/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2155\n",
            "Epoch 95: loss improved from 1.22650 to 1.22450, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 85ms/step - loss: 1.2155\n",
            "Epoch 96/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2110\n",
            "Epoch 96: loss improved from 1.22450 to 1.22059, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2111\n",
            "Epoch 97/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.2122\n",
            "Epoch 97: loss improved from 1.22059 to 1.22038, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 1.2122\n",
            "Epoch 98/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2220\n",
            "Epoch 98: loss improved from 1.22038 to 1.21953, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 85ms/step - loss: 1.2220\n",
            "Epoch 99/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.2077\n",
            "Epoch 99: loss improved from 1.21953 to 1.21695, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - loss: 1.2077\n",
            "Epoch 100/100\n",
            "\u001b[1m764/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.2090\n",
            "Epoch 100: loss improved from 1.21695 to 1.21436, saving model to model_weights_saved.keras\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 84ms/step - loss: 1.2090\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79e268178610>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#recompile the model with saved weights\n",
        "filename='model_weights_saved.keras'\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam')"
      ],
      "metadata": {
        "id": "yfpy8n8niXys"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output of the models back into characters\n",
        "num_to_char=dict((i,c) for i,c in enumerate(chars))"
      ],
      "metadata": {
        "id": "RL2PgijEjU_-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#random seed to help generate\n",
        "start=numpy.random.randint(0,len(x_data)-1)\n",
        "pattern=x_data[start]\n",
        "print(\"Random Seed :\")\n",
        "print(\"\\\"\",''.join([num_to_char[value] for value in pattern]),\"\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV29cNG-jYbn",
        "outputId": "a90ac111-11ad-40fb-f71c-a734d26463d6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed :\n",
            "\" used embers nearly extinguished night came found pleasure fire gave light well heat discovery elemen \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the text\n",
        "for i in range(1000):\n",
        "    x=numpy.reshape(pattern,(1,len(pattern),1))\n",
        "    x=x/float(vocab_len)\n",
        "    prediction=model.predict(x, verbose=0)\n",
        "    index=numpy.argmax(prediction)\n",
        "    result=num_to_char[index]\n",
        "    seg_in=[num_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern=pattern[1:len(pattern)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjdNNlKxjdKX",
        "outputId": "bcb5300c-f5d0-4e68-c875-bfd3c76b7ade"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t rest nature spent wiolently language completely descended also formed formed sufferings remained spoke procure companion saw supply wretch saw felt saw words consideration whose existence soon perceived considerably shall content father gentle breeze sea life appeared despair exes spirits one man soon perceived considerably shall content father gentle breeze sea life appeared despair exes spirits one man soon perceived considerably shall content father gentle breeze sea life appeared despair exes spirits one man soon perceived considerably shall content father gentle breeze sea life appeared despair exes spirits one man soon perceived considerably shall content father gentle breeze sea life appeared despair exes spirits one man soon perceived considerably shall content father gentle breeze sea life appeared despair exes spirits one man soon perceived considerably shall content father gentle breeze sea life appeared despair exes spirits one man soon perceived considerably shall conten"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the generated text for 100 epochs\n",
        "t rest nature spent wiolently language completely descended also formed formed\n",
        "sufferings remained spoke procure companion saw supply wretch saw felt saw words\n",
        "consideration whose existence soon perceived considerably shall content father\n",
        "gentle breeze sea life appeared despair exes spirits one man soon perceived\n",
        "considerably shall content father gentle breeze sea life appeared despair exes\n",
        "spirits one man soon perceived considerably shall content father gentle breeze\n",
        "sea life appeared despair exes spirits one man soon perceived considerably shall\n",
        "content father gentle breeze sea life appeared despair exes spirits one man soon\n",
        "perceived considerably shall content father gentle breeze sea life appeared\n",
        "despair exes spirits one man soon perceived considerably shall content father\n",
        "gentle breeze sea life appeared despair exes spirits one man soon perceived\n",
        "considerably shall content father gentle breeze sea life appeared despair exes\n",
        "spirits one man soon perceived considerably shall conten\n"
      ],
      "metadata": {
        "id": "HS5cXFj2j5Si"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}